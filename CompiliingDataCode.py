import os
import pandas as pd
import re

# Define the folder containing CSV files
downloads_folder = "/Users/mobinariazi/Downloads/Telegram_Scraped_Data"  # Update this path
compiled_csv_path = os.path.join(downloads_folder, "Telegram_Data_Compiled.csv")

# Get all CSV files in the folder
csv_files = [f for f in os.listdir(downloads_folder) if f.endswith(".csv.csv")]

# Keyword Categories
keyword_categories = {
    "Industries_Businesses": [
        "ÙÛŒÙ„ØªØ±Ø´Ú©Ù†", "Ø§ÛŒÙ†ÙÙ„ÙˆØ¦Ù†Ø³Ø±", "Ø¨Ù„Ø§Ú¯Ø±", "Ú©Ø§ÙÙ‡", "Ø±Ø³ØªÙˆØ±Ø§Ù†", "Ú©Ù„ÛŒÙ†ÛŒÚ©", "Ø´Ú©Ù†",
        "Ø§ÛŒÙ†Ø³ØªØ§Ú¯Ø±Ø§Ù…", "Ø³Ø§Ù„Ù†", "Ø¢Ø±Ø§ÛŒØ´Ú¯Ø§Ù‡", "Ø¢Ø±Ø§ÛŒØ´Ú¯Ø±", "Ø³Ø±Ù‚Øª", "Ù‚Ø§Ú†Ø§Ù‚",
        "Ù¾ÛŒØ±Ø§ÛŒØ´Ú¯Ø§Ù‡","ØªØ´Ø±ÛŒÙØ§Øª", "ØµÙ†ÙÛŒ", "Ø¯ÛŒ Ø¬ÛŒ", "ØªØ¨Ù„ÛŒØºØ§Øª", "Ø¨Ø§Ø´Ú¯Ø§Ù‡", "Ø¬ÛŒÙ…", "Ø¨Ø§Ø²Ø§Ø±", "ØªØ¨Ù„ÛŒØºØ§Øª Ù†Ø§Ù…ØªØ¹Ø§Ø±Ù"
    ],
    "Enforcement_Terms": [
        "Ù¾Ù„Ù…Ù¾", "Ø¬Ø±ÛŒÙ…Ù‡", "Ù¾Ù„Ù…Ø¨", "Ø¨Ø³Øª", "ØªØ¹Ø·ÛŒÙ„", "Ø¨Ø±Ø®ÙˆØ±Ø¯", "Ø­Ø¨Ø³", "Ø¯Ø³ØªÚ¯ÛŒØ±", "Ù‡Ø´Ø¯Ø§Ø±",
        "Ø§Ø¬Ø±Ø§ÛŒ", "Ù…Ø³Ø¯ÙˆØ¯", "Ù…Ø­Ú©ÙˆÙ…ÛŒØª", "Ø§Ø®Ø·Ø§Ø±ÛŒÙ‡", "Ù…Ø­Ø±ÙˆÙ…", "Ù…Ù‡Ø±ÙˆÙ…ÙˆÙ…"
    ],
    "Morality_Terms": [
        "Ù‡Ù†Ø¬Ø§Ø±", "Ú©Ø´Ù Ø­Ø¬Ø§Ø¨", "Ø­Ø¬Ø§Ø¨", "Ø¨ÛŒ Ø­Ø¬Ø§Ø¨ÛŒ", "Ù†Ø§Ù…Ù†Ø§Ø³Ø¨",
        "Ø§Ø³ØªØ¹Ù…Ø§Ø±", "Ù…ØªØ®Ù„Ù", "Ø¹ÙØ§Ù", "Ù…Ø¨ØªØ°Ù„", "ÙØ±Ù‡Ù†Ú¯", "ØºØ±Ø¨"
    ],
    "Safety_Terms": [
        "Ø¨Ù‡Ø¯Ø§Ø´Øª", "Ø³Ù„Ø§Ù…ØªÛŒ", "Ø­ÙØ§Ø¸Øª", "Ø§Ù…Ù†ÛŒØª", "Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ", "Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ", "Ø®Ø·Ø±"
    ],
    "Demographic_Terms": [
        "Ø¬ÙˆØ§Ù†", "Ø¯Ø®ØªØ±", "Ú©ÙˆØ¯Ú©Ø§Ù†", "Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡", "Ù¾Ø³Ø±", "Ù¾Ø¯Ø± Ùˆ Ù…Ø§Ø¯Ø±", "ÙˆØ§Ù„Ø¯ÛŒÙ†",
        "Ù…Ø±Ø¯Ø§Ù†", "Ø²Ù†Ø§Ù†"
    ],
    "Operative_Terms": [
        "Ù…Ø¹Ø§ÙˆÙ†Øª", "Ù…Ø¨Ø§Ø±Ø²Ù‡", "Ø±ØµØ¯", "Ù†Ø¸Ø§Ø±Øª", "Ø¨Ø±Ø±Ø³ÛŒ", "ØºÛŒØ± Ù…Ø¬Ø§Ø²", "Ù…Ø¬ÙˆØ²", "Ù‚Ø¶Ø§ÛŒÛŒ",
        "Ø·Ø±Ø­ Ù†ÙˆØ±", "Ú©Ø´Ù", "Ø±Ø³ÛŒØ¯Ú¯ÛŒ Ù‚Ø¶Ø§ÛŒÛŒ", "Ù…Ø¬Ø§Ø²"
    ]
}

# Flatten keyword list
all_keywords = [kw for cat in keyword_categories.values() for kw in cat]

# Initialize lists and dictionaries
df_list = []
file_view_counts = {}  # Store total views per file
skipped_files = []  # Track empty or corrupted files

# Compile all CSVs first
for file in csv_files:
    file_path = os.path.join(downloads_folder, file)
    try:
        # Read CSV with encoding flexibility
        try:
            df = pd.read_csv(file_path, encoding="utf-8-sig", low_memory=False)
        except UnicodeDecodeError:
            df = pd.read_csv(file_path, encoding="utf-16", low_memory=False)

        df["Source File"] = file  # Track file source

        # Ensure "Views" column exists and convert to numeric
        df["Views"] = pd.to_numeric(df.get("Views", 0), errors="coerce").fillna(0).astype(int)
        file_view_counts[file] = df["Views"].sum()

        # Ensure "Message" column exists and convert to string
        df["Message"] = df.get("Message", "").fillna("No Text").astype(str)

        df_list.append(df)  # Append to the list
    except Exception as e:
        print(f"Error loading {file}: {e}")
        skipped_files.append(file)

# Merge all CSVs into one DataFrame
if df_list:
    compiled_df = pd.concat(df_list, ignore_index=True)

    # Add "New Number" column if not already present
    if "New Number" not in compiled_df.columns:
        compiled_df.insert(1, "New Number", range(1, len(compiled_df) + 1))

    # Compute overall totals
    total_messages = len(compiled_df)
    total_views = compiled_df["Views"].sum()

    # Create keyword columns within categories (set all to 0 initially)
    for category, keywords in keyword_categories.items():
        for keyword in keywords:
            compiled_df[keyword] = 0

    # Efficient keyword counting using regex vectorization
    def count_keywords(text):
        return {kw: len(re.findall(rf"\b{re.escape(kw)}\b", text, re.IGNORECASE)) for kw in all_keywords}

    keyword_counts = compiled_df["Message"].apply(count_keywords).apply(pd.Series)
    compiled_df.update(keyword_counts)  # Efficiently update DataFrame with keyword counts

    # Print total occurrences for each keyword category
    print("\nTotal occurrences categorized:")
    for category, keywords in keyword_categories.items():
        print(f"\n**{category.replace('_', ' ')}**")
        for keyword in keywords:
            total_keyword_count = compiled_df[keyword].sum()
            print(f"   ğŸ”‘ {keyword}: {total_keyword_count}")

    # Save the compiled DataFrame
    compiled_df.to_csv(compiled_csv_path, index=False, encoding="utf-8-sig")

    print(f"\nSuccessfully compiled {total_messages} messages from {len(csv_files) - len(skipped_files)} valid CSVs.")
    print(f"Total Views: {total_views}")
    for file, views in list(file_view_counts.items())[:30]:  # Show first 30 files
        print(f"ğŸ“‚ {file}: {views} views")
    print(f"ğŸ’¾ Saved to {compiled_csv_path}")

    if skipped_files:
        print(f"Skipped {len(skipped_files)} files (empty or corrupted):")
        for f in skipped_files[:10]:  # Show first 10 skipped files
            print(f"   - {f}")
else:
    print("No valid CSV files found in the directory.")
